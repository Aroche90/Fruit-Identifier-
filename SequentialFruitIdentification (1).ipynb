{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of SequentialFruitIdentification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Image classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rtPGh2MAVrVa",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E82grprdYPI0",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L1WtoaOHVrVh",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "Connect to Google Drive where images are stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C1nqr-CYY6uw",
        "colab": {}
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Giv0wMQzVrVw"
      },
      "source": [
        "Google Drive Folder Structure for Reference:\n",
        "\n",
        "<pre>\n",
        "<b>Fruit_Images</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>Bananas</b>: [b1.jpeg, b2.jpg, b3.jpeg.jpg ....]\n",
        "    |______ <b>Lemons</b>: [le1.jpg, le2.jpg, le3.jpg ...]\n",
        "    |______ <b>Limes</b>: [li1.jpg, li2.jpg, li3.jpg ...]\n",
        "    |______ <b>Lychees</b>: [ly1.jpg, ly2.jpg, ly3.jpg ...]\n",
        "    |______ <b>Peaches</b>: [pe1.jpg, pe2.jpg, pe3.jpg ...]\n",
        "    |______ <b>Pineapples</b>: [pi1.jpg, pi2.jpg, pi3.jpg ...]\n",
        "    |______ <b>Pommegranites</b>: [po1.jpg, po2.jpg, po3.jpg ...]\n",
        "    |______ <b>Raspberries</b>: [r1.jpg, r2.jpg, r3.jpg ...]\n",
        "    |______ <b>RedApples</b>: [a1.jpg, a2.jpg, a3.jpg ...]\n",
        "    |______ <b>Strawberries</b>: [s1.jpg, s2.jpg, s3.jpg ...]\n",
        "   \n",
        "|__ <b>test</b>\n",
        "  |______ <b>Bananas</b>: [b1.jpeg, b2.jpg, b3.jpeg]\n",
        "    |______ <b>Lemons</b>: [le1.jpg, le2.jpg, le3.jpg]\n",
        "    |______ <b>Limes</b>: [li1.jpg, li2.jpg, li3.jpg]\n",
        "    |______ <b>Lychees</b>: [ly1.jpg, ly2.jpg, ly3.jpg]\n",
        "    |______ <b>Peaches</b>: [pe1.jpg, pe2.jpg, pe3.jpg]\n",
        "    |______ <b>Pineapples</b>: [pi1.jpg, pi2.jpg, pi3.jpg]\n",
        "    |______ <b>Pommegranites</b>: [po1.jpg, po2.jpg, po3.jpg]\n",
        "    |______ <b>Raspberries</b>: [r1.jpg, r2.jpg, r3.jpg]\n",
        "    |______ <b>RedApples</b>: [a1.jpg, a2.jpg, a3.jpg]\n",
        "    |______ <b>Strawberries</b>: [s1.jpg, s2.jpg, s3.jpg]\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "Saving the file paths to \"Training\" and \"Testing\" sets as variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sRucI3QqVrVy",
        "colab": {}
      },
      "source": [
        "\n",
        "PATH= ('/content/drive/My Drive/Fruit_Images/')\n",
        "train_dir = os.path.join(PATH, 'train/')\n",
        "test_dir = os.path.join(PATH, 'test/')\n",
        "X=train_dir\n",
        "y=train_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Utv3nryxVrV0",
        "colab": {}
      },
      "source": [
        "train_Bananas_dir = os.path.join(train_dir, 'Bananas')  # directory with our training Banana Pics\n",
        "train_Lemons_dir = os.path.join(train_dir, 'Lemons')  # directory with our training Lemon Pics\n",
        "train_Limes_dir = os.path.join(train_dir, 'Limes')  # directory with our training Lime Pics\n",
        "train_Lychees_dir = os.path.join(train_dir, 'Lychees')  # directory with our training Lychee Pics\n",
        "train_Peaches_dir = os.path.join(train_dir, 'Peaches')  # directory with our training Peach Pics\n",
        "train_Pineapples_dir = os.path.join(train_dir, 'Pineapples')  # directory with our training Pineapple Pics\n",
        "train_Pommegranites_dir = os.path.join(train_dir, 'Pomegranites')  # directory with our training Pommegranite Pics\n",
        "train_Raspberries_dir = os.path.join(train_dir, 'Raspberries')  # directory with our training Raspberry Pics\n",
        "train_Apples_dir = os.path.join(train_dir, 'RedApples')  # directory with our training Red Apple Pics\n",
        "train_Strawberries_dir = os.path.join(train_dir, 'Strawberries')  # directory with our training Strawberry Pics\n",
        "\n",
        "test_Bananas_dir = os.path.join(test_dir, 'Bananas')  # directory with our test Banana pictures\n",
        "test_Lemons_dir = os.path.join(test_dir, 'Lemons')  # directory with our test Lemon pictures\n",
        "test_Limes_dir = os.path.join(test_dir, 'Limes')  # directory with our test Lime pictures\n",
        "test_Lychees_dir = os.path.join(test_dir, 'Lychees')  # directory with our test Lychee pictures\n",
        "test_Peaches_dir = os.path.join(test_dir, 'Peaches')  # directory with our test Peach pictures\n",
        "test_Pineapples_dir = os.path.join(test_dir, 'Pineapples')  # directory with our test Pineapple pictures\n",
        "test_Pommegranites_dir = os.path.join(test_dir, 'Pomegranites')  # directory with our test Pommegranite pictures\n",
        "test_Raspberries_dir = os.path.join(test_dir, 'Raspberries')  # directory with our test Raspberry pictures\n",
        "test_Apples_dir = os.path.join(test_dir, 'RedApples')  # directory with our test Apple pictures\n",
        "test_Strawberries_dir = os.path.join(test_dir, 'Strawberries')  # directory with our test Strawberry pictures\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LblUYjl-VrV3"
      },
      "source": [
        "See how many Fruit Images are in the **Train** and **Test** directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc4u8e9hVrV4",
        "colab": {}
      },
      "source": [
        "num_Bananas_tr = len(os.listdir(train_Bananas_dir))\n",
        "num_Lemons_tr = len(os.listdir(train_Lemons_dir))\n",
        "num_Limes_tr = len(os.listdir(train_Limes_dir))\n",
        "num_Lychees_tr = len(os.listdir(train_Lychees_dir))\n",
        "num_Peaches_tr = len(os.listdir(train_Peaches_dir))\n",
        "num_Pineapples_tr = len(os.listdir(train_Pineapples_dir))\n",
        "num_Pommegranites_tr = len(os.listdir(train_Pommegranites_dir))\n",
        "num_Raspberries_tr = len(os.listdir(train_Raspberries_dir))\n",
        "num_Apples_tr = len(os.listdir(train_Apples_dir))\n",
        "num_Strawberries_tr = len(os.listdir(train_Strawberries_dir))\n",
        "\n",
        "\n",
        "num_Bananas_test = len(os.listdir(test_Bananas_dir))\n",
        "num_Lemons_test = len(os.listdir(test_Lemons_dir))\n",
        "num_Limes_test = len(os.listdir(test_Limes_dir))\n",
        "num_Lychees_test = len(os.listdir(test_Lychees_dir))\n",
        "num_Peaches_test = len(os.listdir(test_Peaches_dir))\n",
        "num_Pineapples_test = len(os.listdir(test_Pineapples_dir))\n",
        "num_Pommegranites_test = len(os.listdir(test_Pommegranites_dir))\n",
        "num_Raspberries_test = len(os.listdir(test_Raspberries_dir))\n",
        "num_Apples_test = len(os.listdir(test_Apples_dir))\n",
        "num_Strawberries_test = len(os.listdir(test_Strawberries_dir))\n",
        "\n",
        "\n",
        "total_train = num_Bananas_tr + num_Lemons_tr + num_Limes_tr + num_Lychees_tr + num_Peaches_tr + num_Pineapples_tr + num_Pommegranites_tr + num_Raspberries_tr + num_Apples_tr + num_Strawberries_tr\n",
        "total_test = num_Bananas_test + num_Lemons_test + num_Limes_test + num_Lychees_test + num_Peaches_test + num_Pineapples_test + num_Pommegranites_test + num_Raspberries_test + num_Apples_test + num_Strawberries_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g4GGzGt0VrV7",
        "colab": {}
      },
      "source": [
        "  print(\"Total training images:\", total_train)\n",
        "print(\"Total testing images:\", total_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Lp-0ejxOtP1"
      },
      "source": [
        "Setting up variables to use while pre-processing the dataset and training the Neural Network.</br>\n",
        "**Batch Size** relates to:\n",
        "</br>\n",
        "**Epochs** relates to:\n",
        "</br>\n",
        "**IMG HEIGHT** and **IMG WIDTH** specify the dimensions of the images we will be pre-processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NqNselLVrWA",
        "colab": {}
      },
      "source": [
        "batch_size =300\n",
        "epochs = 10\n",
        "IMG_HEIGHT = 100\n",
        "IMG_WIDTH = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "INn-cOn1VrWC"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Jfk6aSAVrWD"
      },
      "source": [
        "Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
        "\n",
        "1. Read images from the disk.\n",
        "2. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
        "3. Convert them into floating point tensors.\n",
        "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
        "\n",
        "Fortunately, all these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`. It can read images from disk and preprocess them into proper tensors. It will also set up generators that convert these images into batches of tensors—helpful when training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "syDdF_LWVrWE",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1/255) # Generator for our training data\n",
        "test_image_generator = ImageDataGenerator(rescale=1/255) # Generator for our validation data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLciCR_FVrWH"
      },
      "source": [
        "After defining the generators for training and validation images, the `flow_from_directory` method load images from the disk, applies rescaling, and resizes the images into the required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pw94ajOOVrWI",
        "colab": {}
      },
      "source": [
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory= (train_dir),\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='sparse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2oUoKUzRVrWM",
        "colab": {}
      },
      "source": [
        "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=(test_dir),\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='sparse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hyexPJ8CVrWP"
      },
      "source": [
        "### Visualize training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "60CnhEL4VrWQ"
      },
      "source": [
        "Visualize the training images by extracting a batch of images from the training generator—which is 32 images in this example—then plot five of them with `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3f0Z7NZgVrWQ",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "49weMt5YVrWT"
      },
      "source": [
        "The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels. Discard the labels to only visualize the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JMt2RES_VrWU",
        "colab": {}
      },
      "source": [
        "\n",
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_VVg_gEVrWW",
        "colab": {}
      },
      "source": [
        "\n",
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5Ej-HLGVrWZ"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wEgW4i18VrWZ"
      },
      "source": [
        "The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a `relu`` activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSQwVznpQxOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F15-uwLPVrWa",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(100, 3,activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(200, 3, activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(400, 3, activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='sigmoid'),\n",
        "    Dense(1)\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PI5cdkMQVrWc"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "For this tutorial, choose the *ADAM* optimizer and *binary cross entropy* loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Mg7_TXOVrWd",
        "colab": {}
      },
      "source": [
        "# model.compile(optimizer='rmsprop',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2YmQZ3TAVrWg"
      },
      "source": [
        "### Model summary\n",
        "\n",
        "View all the layers of the network using the model's `summary` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vtny8hmBVrWh",
        "colab": {}
      },
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N06iqE8VVrWj"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oub9RtoFVrWk"
      },
      "source": [
        "Use the `fit` method of the `ImageDataGenerator` class to train the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KSF2HqhDVrWk",
        "colab": {}
      },
      "source": [
        "\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,   \n",
        "    validation_data=test_data_gen,\n",
        "    validation_steps=total_test // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ojJNteAGVrWo"
      },
      "source": [
        "### Visualize training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LZPYT-EmVrWo"
      },
      "source": [
        "Now visualize the results after training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K6oA77ADVrWp",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Test Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Testing Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Test Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Testing Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}